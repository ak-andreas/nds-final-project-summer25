{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f29516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Tuning Function Fitting...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'stim_filtered is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m stim_data_path = \u001b[33m'\u001b[39m\u001b[33m./data/preprocessed/deconv_and_sta.npz\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     25\u001b[39m stim_data = np.load(stim_data_path, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m stim_filtered = \u001b[43mstim_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstim_filtered\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m stim_table_filtered_df = pd.DataFrame(stim_data[\u001b[33m'\u001b[39m\u001b[33mstim_table_filtered\u001b[39m\u001b[33m'\u001b[39m], columns=stim_data[\u001b[33m'\u001b[39m\u001b[33mstim_table_columns\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully loaded stimulus data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstim_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/tue-summer-2025-oasis/lib/python3.11/site-packages/numpy/lib/npyio.py:263\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    261\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.zip.read(key)\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a file in the archive\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'stim_filtered is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "# Add this code to a new cell in your 03-tuning-function-fitting.ipynb notebook\n",
    "\n",
    "# --- Phase 3: Tuning Function Fitting ---\n",
    "# Goal: Load the outputs from the previous phases and use them to estimate\n",
    "# the spatio-temporal receptive field (STRF) for each neuron.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils as U # Assuming your utility functions are in utils.py\n",
    "import importlib\n",
    "importlib.reload(U) # Use this if you've made changes to utils.py\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"Starting Phase 3: Tuning Function Fitting...\")\n",
    "\n",
    "# --- Step 1: Load Inputs from Previous Notebooks ---\n",
    "# We need the outputs from both preprocessing and spike inference.\n",
    "\n",
    "try:\n",
    "    # --- Load Stimulus Data (from 00-background.ipynb) ---\n",
    "    # This data is required for the fitting process.\n",
    "    stim_data_path = './data/preprocessed/deconv_and_sta.npz'\n",
    "    stim_data = np.load(stim_data_path, allow_pickle=True)\n",
    "    stim_filtered = stim_data['stim_filtered']\n",
    "    stim_table_filtered_df = pd.DataFrame(stim_data['stim_table_filtered'], columns=stim_data['stim_table_columns'])\n",
    "    print(f\"Successfully loaded stimulus data from: {stim_data_path}\")\n",
    "\n",
    "    # --- Load Spike Inference Data (from 02-spike-inference.ipynb) ---\n",
    "    # The output file from the spike inference notebook is timestamped,\n",
    "    # so we find the most recent one in the directory.\n",
    "    spike_inference_dir = 'data/spike_inference/'\n",
    "    \n",
    "    # Find all .npz files in the directory\n",
    "    list_of_files = glob.glob(os.path.join(spike_inference_dir, '*.npz'))\n",
    "    if not list_of_files:\n",
    "        raise FileNotFoundError(f\"No spike inference output files found in '{spike_inference_dir}'\")\n",
    "    \n",
    "    # Get the most recent file based on creation time\n",
    "    latest_spike_file = max(list_of_files, key=os.path.getctime)\n",
    "    \n",
    "    print(f\"Loading latest spike inference data from: {latest_spike_file}\")\n",
    "    spike_data = np.load(latest_spike_file)\n",
    "    inferred_spikes = spike_data['inferred_spikes']\n",
    "    t_filtered = spike_data['time_vector'] # Use the correct key 'time_vector'\n",
    "    \n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: Could not find a necessary input file: {e}\")\n",
    "    print(\"Please ensure you have run the previous notebooks (00 and 02) and saved their outputs correctly.\")\n",
    "    # Stop execution if files are missing\n",
    "    raise\n",
    "\n",
    "# --- Step 2: Run the Receptive Field Fitting Pipeline ---\n",
    "# This section calls the functions from your utils.py file in sequence.\n",
    "\n",
    "# 2a. Bin the inferred spikes to align with stimulus frames\n",
    "binned_spikes = U.bin_spikes_to_frames(inferred_spikes, t_filtered, stim_table_filtered_df)\n",
    "\n",
    "# 2b. Prepare the stimulus matrix by flattening the frames\n",
    "flattened_stim, stim_h, stim_w = U.prepare_stimulus_matrix(stim_filtered)\n",
    "\n",
    "# 2c. Define the time lags and fit the STRF for all neurons\n",
    "lags_to_test = [0, 1, 2, 3, 4]\n",
    "all_rfs_spatiotemporal = U.fit_all_neurons_rfs(binned_spikes, flattened_stim, lags_to_test)\n",
    "\n",
    "# 2d. Extract the primary spatial component from each STRF using SVD\n",
    "all_rfs_spatial = U.extract_spatial_rfs_svd(all_rfs_spatiotemporal, stim_h, stim_w)\n",
    "\n",
    "print(\"\\nReceptive field fitting and analysis complete!\")\n",
    "\n",
    "\n",
    "# --- Step 3: Verification Plot ---\n",
    "# Visualize the results for one neuron to confirm the pipeline worked.\n",
    "neuron_to_plot = 10 # You can change this to inspect different neurons\n",
    "\n",
    "U.visualize_neuron_rf(\n",
    "    neuron_id=neuron_to_plot,\n",
    "    spatiotemporal_rf=all_rfs_spatiotemporal[neuron_to_plot],\n",
    "    spatial_rf=all_rfs_spatial[neuron_to_plot],\n",
    "    delta=lags_to_test\n",
    ")\n",
    "\n",
    "# --- Step 4: Save the output of this notebook ---\n",
    "# Saving the results is crucial so you don't have to re-run this computationally\n",
    "# intensive step for the final analysis in the next notebook.\n",
    "output_path = 'data/preprocessed/rf_fitting_output.npz'\n",
    "np.savez_compressed(\n",
    "    output_path,\n",
    "    all_rfs_spatiotemporal=np.array(all_rfs_spatiotemporal),\n",
    "    all_rfs_spatial=np.array(all_rfs_spatial)\n",
    ")\n",
    "print(f\"\\nSuccessfully saved receptive field results to: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2da7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tue-summer-2025-oasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
